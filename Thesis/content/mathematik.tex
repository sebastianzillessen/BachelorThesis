%Die Angabe des schlauen Spruchs auf diesem Wege funtioniert nur,
%wenn keine Änderung des Kapitels mittels den in preambel/chapterheads.tex
%vorgeschlagenen Möglichkeiten durchgeführt wurde.
%\setchapterpreamble[u]{%
%\dictum[Albert Einstein]{Insofern sich die Sätze der Mathematik auf die Wirklichkeit beziehen, sind sie nicht sicher, und insofern sie sicher sind, beziehen sie sich nicht auf die Wirklichkeit. Mathematische Theorien über die Wirklichkeit sind immer ungesichert - wenn sie gesichert sind, handelt es sich nicht um die Wirklichkeit.}
%}
\chapter{Mathematische Ausarbeitung}
\label{chap:maths}
Zur Lösung des \gls{LGS} aus \autoref{eq:energy:weights} soll in der vorliegenden Arbeit ein anderes Verfahren verwendet werden. Hierbei wird das Lösen nach $\b g$ und $F_i$ in zwei Teilprobleme zerlegt, welche alternierend gelöst werden. Der Vorteil dieses Ansatzes ist, dass die gesamten Bildinformationen aus der Belichtungsserie verwendet werden können. Dies ist möglich, da die entstehenden Gleichungssysteme sehr dünn besetzt sind und effizient gelöst werden können. Die Struktur des alternierenden Vorgehens ist im \autoref{alg:alternierend:basic} beschrieben.

\begin{Algorithmus} %Die Umgebung nur benutzen, wenn man den Algorithmus ähnlich wie Graphiken von TeX platzieren lassen möchte
\caption{Alternierendes Lösen nach $g(k)$ und $F_i$}
\label{alg:alternierend:basic}
\begin{algorithmic}
\Function{SolveHDR}{$Z_{ij}$, $\ln \Delta t_j$, $N$, $P$}
	\State $g \gets initG()$
	\While{$g$ changes} 
		\State $\b F \gets solveF(\b F, \b g, Z_{ij}, \ln \Delta t_j, N, P)$ 
		\State $\b g \gets solveG(\b F, \b g, Z_{ij}, \ln \Delta t_j, N, P)$
	\EndWhile
	\State \Return [$\b g$, $\b F$]
\EndFunction
\end{algorithmic}
\end{Algorithmus}

Dieser Algorithmus läuft darauf hinaus, dass aus einer bestehenden Zwischenlösung immer eine neue Näherung der anderen Unbekannten berechnet wird, solange bis das Resultat konvergiert. Bei gegebenem $\b g$ wird eine neue Instanz von $\b F$ berechnet, die dann wieder für die Schätzung von $\b g$ verwendet wird. 

Darüber hinaus kann durch dieses Verfahren neben der Schätzung der Kamera-Antwortkurve auch gleichzeitig die \gls{Radiance Map} des \gls{HDR}-Bildes mit berechnet werden. Dadurch spart man sich die anschließende Umrechnung der Bildpunkte mittels der Funktion $\b g$ und ist außerdem in der Lage Forderungen an $\b F$ zu stellen.

In den nachfolgenden Abschnitten werden häufig Approximationen für die erste und zweite Ableitung verwendet. Dass es sich hierbei deswegen in der Regel um keine exakte Gleichheit ($=$) handelt, sondern vielmehr um eine Annäherung ($\approx$) sei hier erwähnt. Es wird im Nachfolgenden aus Gründen der Lesbarkeit darauf verzichtet dies kenntlich zu machen.


% --------------------------------------------------------------------------------------------------------------
\section{Optimierungsansatz}
\label{sec:ansatz}
Die \autoref{eq:energy:weights} dient als Grundlage für den Optimierungsansatz des gesamten Verfahrens. Da diese Energiefunktion minimiert werden soll, sind partielle Ableitungen nach $\b g(k)$ bzw. $F_i$ notwendig. Die vorkommenden Ableitungen zweiter Ordnung werden mittels der zentralen Differenz $\b g''(k) = \b g(k-1) - 2\b g(k) +\b g(k+1)$ diskretisiert. Dies führt zu nachfolgender Umstellung der Energiefunktion:

\begin{align}
\Omega =& \sum \limits_{i=0}^{N-1} \sum \limits_{j=0}^{P-1}w^2(Z_{ij})\cdot[\b g(Z_{ij}) - F_i - \ln \Delta t_j]^2 + \lambda  \sum \limits_{z=Z_{min}+1}^{Z_{max}-1} [w(z) \cdot \b g''(z)]^2\\
\label{eq:energy:diskret}
\begin{split}
 &\qquad= \underbrace{\sum \limits_{i=0}^{N-1} \sum \limits_{j=0}^{P-1}w^2(Z_{ij})\cdot[\b g(Z_{ij}) - F_i - \ln \Delta t_j]^2}_{\Phi} \\
 &\qquad+ \lambda \underbrace{ \sum \limits_{z=Z_{min}+1}^{Z_{max}-1} w^2(z) \cdot \overbrace{
 	[\b g(z-1)-2\b g(z)+\b g(z+1)]^2
 }^{
 	\text{Diskretisierung von }g''(k)
 }
 }_{\Theta}
 \end{split}	
 \end{align}
In den folgenden Herleitungen taucht häufig der Faktor $2$ auf. Dieser entsteht durch das Ableiten der quadratischen Bestrafungsfunktionen. Er taucht in der Regel in allen Summanden von $\partial \Omega$ auf und kann deswegen gekürzt werden. In besonderen Fällen (wie z.B. der Erweiterung um robuste Bestrafungsterme, siehe \autoref{sec:robustheit}) ist dies nicht der Fall. Dann werden diese Faktoren separat behandelt.

% --------------------------------------------------------------------------------------------------------------
\subsection{Gleichungssystem für $\b g$}
Um nun das \gls{LGS} zur Lösung nach $\b g$ aufzustellen, muss $\Omega$ zunächst partiell nach $\b g(k) \; \forall k \in [0,255]$ abgeleitet werden. Hierbei kann man die Ableitungen nach $\Phi$ und $\Theta$ zunächst separat betrachten:

\begin{align}
\label{eq:energy:partial}
\frac{\partial \Omega}{\partial \b g(k)} 
	& = \frac{\partial \Phi}{\partial \b g(k)} +\frac{\partial \Theta}{\partial \b g(k)}
\end{align}
	
	Bei der Ableitung von $\Phi$ kommt eine Einschaltfunktion $\delta_{z=k}$ zum Einsatz, die wie folgt definiert ist:

\begin{align}
	\delta_{z=k} &= \begin{cases}
    		1 \mbox{ wenn } z = k\\
	    0 \mbox{ sonst}
    \end{cases}
\end{align}

Unter Zuhilfenahme dieser Funktion kann die partielle Ableitung von $\Phi$ wie folgt notiert werden:

\begin{align}
\frac{\partial \Phi}{\partial \b g(k)} 
	&= 2\cdot w^2(k) \cdot \sum \limits_{i=0}^{N-1} \sum \limits_{j=0}^{P-1} \cdot[\b g(k) - F_i - \ln \Delta t_j]\cdot \delta_{Z_{ij}=k}\\
&=2\cdot w^2(k) \cdot \b g(k) \sum \limits_{i=0}^{N-1} \sum \limits_{j=0}^{P-1}\delta_{Z{ij}=k} - 2\cdot w^2(k)\cdot\sum \limits_{i=0}^{N-1} \sum \limits_{j=0}^{P-1}\delta_{Z_{ij}=k}(F_i - \ln \Delta t_j)\\
\label{eq:1}
 &= \underbrace{
        w^2(k) \sum_{i=0}^{N-1} \sum_{j=0}^{P-1}(\delta_{Z_{ij}=k})
    }_{\mbox{Matrixeintrag }a_k} 
    \cdot \b g(k) - 
    \underbrace{
        w^2(k) \sum_{i=0}^{N-1} \sum_{j=0}^{P-1}(F_i - \ln \Delta t_j)\delta_{Z_{ij}=k}
    }_{\mbox{Vektoreintrag }b_k}
\end{align}
    
Dieses System kann in Matrixschreibweise umformuliert werden, wobei die Koeffizienten der Matrix aus den einzelnen partiellen Ableitungen gewonnen werden können:
    \begin{align}
    \label{eq:matrix:data}
&
\begin{pmatrix}
\ddots & 0& 0\\
0 & a_k & 0\\
0 & 0 & \ddots
\end{pmatrix}
 \cdot \begin{pmatrix}
 \vdots\\
 \b g(k)\\
 \vdots
 \end{pmatrix} - 
\begin{pmatrix}
 \vdots\\
 b_k\\
 \vdots
 \end{pmatrix} 
\end{align}


Anschließend betrachten wir den Glattheitsterm $\Theta$. Auch dieser muss partiell nach $\b g(k)$ abgeleitet werden. Aus Gründen der Vereinfachung wurden in den folgenden Berechnungen $Z_{min} = 0$ und $Z_{max} = 255$ angenommen. In der \autoref{eq:energy:diskret} wurde der Gewichtungsfaktor für den Glattheitsterm $\lambda$ absichtlich nicht in $\Theta$ eingebunden, da dieser bei der Herleitung keine Rolle spielt. Der Faktor $\lambda$ wird am Ende wieder hinzugefügt. Bei der partiellen Ableitung des Glattheitsterms muss hier besonders auf die Randbedingungen geachtet werden, dort verhalten sich die partiellen Ableitungen anders:


\begin{align}
\label{eq:partials:smoothness:0}
\frac{\partial \Theta}{\partial \b g(0)} =& w^2(1)\cdot \b g(0) -2w^2(1)\cdot \b g(1) + w^2(1)\cdot \b g(2)\\
\label{eq:partials:smoothness:1}
\frac{\partial \Theta}{\partial \b g(1)} = &-2w^2(1)\cdot \b g(0) \nonumber \\
        &+[4w^2(1)+w^2(2)]\cdot \b g(1) \nonumber \\
        &- 2 [w^2(1)+w^2(2)]\cdot \b g(2) \nonumber \\
        &+ w^2(2)\cdot \b g(3) \\
\label{eq:partials:smoothness:k}
\frac{\partial \Theta}{\partial \b g(k)} =& 
        w^2(k-1)\cdot \b g(k-2)\nonumber\\
        &- 2[w^2(k-1)+2w^2(k)]\cdot \b g(k-1) \nonumber\\
        &+ [w^2(k-1)+4w^2(k)+w^2(k+1)]\cdot \b g(k)\nonumber\\ 
        &- 2[w^2(k)+w^2(k+1)] \cdot \b g(k+1) \nonumber\\
        &+ w^2(k+1)\cdot \b g(k+1) \qquad \forall k \in [2,253]\\
\label{eq:partials:smoothness:254}
\frac{\partial \Theta}{\partial \b g(254)} =& w^2(253)\cdot \b g(252) \nonumber \\
        & -2 (w^2(253)+w^2(254))\cdot \b g(253) \nonumber \\
        & +(w^2(253)+4 w^2(254)) \cdot \b g(254)\nonumber \\
        & -2 w^2(254)\cdot \b g(255)\\
\label{eq:partials:smoothness:255}
\frac{\partial \Theta}{\partial \b g(255)} &= 
    w^2(254)\cdot \b g(253) 
    - 2 w^2(254)\cdot \b g(254) 
    + w^2(254)\cdot \b g(255)
\end{align}

Auch diese Gleichungen lassen sich wieder in Matrixschreibweise umformulieren (siehe \autoref{eq:matrix:smoothness}). Die  Koeffizienten der Matrix gehen aus obigen Gleichungen hervor (z.B. $d_{0,0} = w^2(1), \; d_{1,-1} = -2w^2(1), \dots$). Der Faktor $\lambda$ wurde hier wieder mit hineingezogen (siehe \autoref{eq:energy:diskret}). Bei der Matrix $D_4$ handelt es sich um eine diskrete Approximation der vierten Ableitung.

\begin{align}
\label{eq:matrix:smoothness}
\lambda
\underbrace{
\begin{pmatrix}
d_{0,0} & d_{0,1} & d_{0,2} & 0 &\cdots\\
d_{1,-1} & d_{1,0} & d_{1,1} & d_{1,2} & 0 &\cdots\\
&  & \ddots &  \\
\cdots  & d_{k,-2} & d_{k,-1} & d_{k,0}&d_{k,1} &d_{k,2} & \cdots\\
&&&&\ddots&&&\\
&&&d_{254,-2}&d_{254,-1}&d_{254,0}&d_{254,1}\\
&&&&d_{255,-2}&d_{255,-1}&d_{255,0}\\
\end{pmatrix}}_{\mbox{Matrix } D_4}
\cdot
\begin{pmatrix}
\vdots\\
\b g(k)\\
\vdots
\end{pmatrix}
\end{align}

Die Gleichungen \ref{eq:1} und \ref{eq:partials:smoothness:0} -- \ref{eq:partials:smoothness:255} (bzw. die Matrixschreibweisen aus den Gleichungen \ref{eq:matrix:data} und \ref{eq:matrix:smoothness}) ergeben zusammen mit der Ausgangssituation wie sie in \autoref{eq:energy:partial} beschrieben ist, das folgende endgültige Gleichungssytem für $\b g$, welches ebenfalls in Matrix-Notation aufgestellt werden kann:
 
\begin{align}
\label{eq:g:lgs}
\underbrace{[A+\lambda D_4]}_{\mbox{Matrix M}}\cdot \b g = b
\end{align}

Zu beachten ist, dass $M$ eine \gls{Pentadiagonal-Matrix} ist. Dies kann beim Lösen des \gls{LGS} genutzt werden, indem eine spezialisierte Variante der LU-Zerlegung verwendet wird (siehe \autoref{sec:maths:lu}).

Außerdem führt die Zerlegung des Problems in das separierte Lösen nach $\b g$ und $\b E$ dazu, dass die ursprünglich erwähnte Eigenschaft der unendlichen Anzahl von Lösungen (siehe \autoref{sec:eindeutigkeit}) nicht mehr besteht, da die beiden Schritte des Verfahrens separat und alternierend ausgeführt werden und immer eine konkrete Näherungslösung der jeweils anderen Unbekannten vorliegt, die implizit eine (unbekannte) Verschiebung enthält.
Um diese Problematik zu umgehen, wird deshalb nach der Berechnung von $\b g$ die Kurve immer so verschoben, dass $\b g(Z_{mid}) = 0$ gilt. Diese Verschiebung wird durch die folgende Vorschrift durchgeführt:

\begin{align}
\tilde{\b g}(k) &= \b g(k)-\b g(Z_{mid})\, \forall k \in [0,255]
\end{align}

Damit ist sichergestellt, dass alle Antwortkurven, die durch das Verfahren berechnet werden, vergleichbar und eindeutig sind.


% --------------------------------------------------------------------------------------------------------------

\subsection{Lösen nach $\b F$}
Im Gegensatz zu $\b g$ kann $\b F$ ohne ein \gls{LGS} berechnet werden, da es punktweise definiert ist. Die Berechnungsvorschrift für $F_i$ resultiert aus der partiellen Ableitung der Energiefunktion aus \autoref{eq:energy:diskret} nach $F_i$ und lautete:
\begin{align}
\label{eq:fi:basic}
    F_i =& \frac{\sum \limits_{j=0}^{P-1} (\b g(Z_{ij})-\ln \Delta t_j)\cdot w^2(Z_{ij})}{\sum \limits_{j=0}^{P-1} w^2(Z_{ij})}
\end{align}

Mithilfe dieser Funktion kann nun nach errechnetem $\b g$ auch die neue Instanz von $\b F$ berechnet werden, die dann im Zuge des alternierenden Verfahrens wieder Eingabe für die Berechnung von $\b g$ ist.


Nach der grundsätzlichen Vorstellung des Verfahrens sollen nun die möglichen Erweiterungen beschrieben und formal spezifiziert werden. Dazu wird das Standard-Verfahren schrittweise erweitert.

% ----------------------------------------------------------------------------------

\section{Erweiterung um Monotonie-Eigenschaft}
\label{sec:monotonie}

Im Ansatz von Debevec und Malik wird für die Funktion $f$ angenommen, dass sie monoton und damit invertierbar ist. Für die diskrete Funktion $\b g$ wird dies jedoch nicht explizit gefordert. Aus physikalischer und radiometrischer Sicht muss $\b g$ jedoch ebenfalls (streng) monoton sein. Deshalb wird nachfolgend eine erste Erweiterung des Algorithmus mit einer Forderung an die Monotonie von $\b g$ vorgestellt. Dies lässt sich über die Energiefunktion $\Omega$ als weiteren Bestrafungsterm $\Gamma$ realisieren. Damit erhalten wir die neue Funktion $\tilde{\Omega}$: 

\begin{align}
\tilde{\Omega} &= \Omega + \underbrace{\mu \sum \limits_{z=1}^{255} w^2(z) [(\phi_{\b g'<0}(z)\cdot \b g'(z)]^2}_{\mbox{Monotonie-Forderung } \Gamma} = \Omega + \Gamma
\end{align}

Die in dieser Gleichung vorkommende Funktion $\phi_{\b g'<0}(z)$ ist eine Indikatorfunktion, die immer dann aktiv wird, falls die Monotonie der Kurve $\b g$ an einer Stelle verletzt ist, und ist folgendermaßen definiert: 

\begin{align}
\phi_{\b g'<0}(z) &= 
    \begin{cases} 
        1, \; \mbox{falls } \b g'(z) < 0\\ 
        0 \; \mbox{sonst}
    \end{cases}
\end{align}

Hier wird ebenfalls der Least-Squares-Ansatz (quadratische Bestrafungsfunktion) verwendet, welcher auch schon im Standard-Verfahren zum Einsatz kommt (siehe \autoref{eq:energy:weights}). Dadurch werden Abweichungen von der Monotonie quadratisch bestraft. 

Da $\b g'(z)$ bei der Berechnung von $\b g$ nicht bekannt ist, wird für die Indikatorfunktion die Instanz $\b g$ aus der vorherigen Iteration verwendet. Durch die Diskretisierung mit der einseitigen finiten Differenz $\b g'(z) = \b g(z)-\b g(z-1)$ erhält man dadurch den zusätzlichen Summanden $\Gamma$:

\begin{align}
\Gamma = & \mu \sum_{z=1}^{255} w^2(z) \cdot \phi^2_{\b g'<0}(z) \cdot (\b g(z)- \b g(z-1))^2
\end{align}

Auch dieser muss im Zuge der Minimierung der Energiefunktion partiell nach $\b g(k)$ abgeleitet werden, was zu folgenden Gleichungen führt:

\begin{align}
\label{eq:mon:diskret}
\frac{\partial \Gamma}{\partial \b g(0)} =& -2\mu w^2(1) \cdot \phi^2_{\b g'<0}(1)\cdot(\b g(1)-\b g(0))\\
\frac{\partial \Gamma}{\partial \b g(k)} 
        =& 2\mu w^2(k) \cdot \phi^2_{\b g'<0}(k)\cdot(\b g(k)-\b g(k-1)) \nonumber \\
         &- 2 \mu w^2(k+1) \cdot \phi^2_{\b g'<0}(k+1)\cdot(\b g(k+1)-\b g(k))
        \; , \; \forall k \in [1,254]\\
        \label{eq:mon:diskret:last}
\frac{\partial \Gamma}{\partial \b g(255)} =& -2\mu w^2(255) \cdot \phi^2_{\b g'<0}(255)\cdot(\b g(255)-\b g(254))
\end{align}
Aus den Gleichungen \ref{eq:mon:diskret} -- \ref{eq:mon:diskret:last} lässt sich nun wieder eine Matrix mit folgender Stuktur erzeugen (hier wurde $\phi^2_{\b g'<0}(k) = \phi^2_{\b g'}(k)$ zur Kürzung verwendet):
\small
\begin{align}
2\mu 
\underbrace{\begin{pmatrix}
-w^2(1)\phi^2_{\b g'}(1) &w^2(1)\phi^2_{\b g'}(1) & 0 & \cdots\\
& \ddots\\
\cdots & -w^2(k)\phi^2_{\b g'}(k) & 
\begin{smallmatrix}
w^2(k)\phi^2_{\b g'}(k) \\+ w^2(k+1)\phi^2_{\b g'}(k+1)
\end{smallmatrix}
 & -w^2(k+1)\phi^2_{\b g'}(k+1) & \cdots \\
& & \ddots\\
& \cdots &  0 & w^2(255)\phi^2_{\b g'}(255) & - w^2(255)\phi^2_{\b g'}(255) \\
\end{pmatrix}}_{\mbox{Matrix } C}
\end{align}
\normalsize

Diese Berechnung kann auch über Matritzenmultiplikation erreicht werden. $D$ ist dabei eine Matrix, welche die erste Ableitung approximiert. $V$ ist eine Diagonal-Matrix mit $v_{i,i} = \phi_{\b g'<0}(i)$. $W$ ist die Diagonal-Matrix der Gewichte mit $w_{i,i} = w(i)$. Die damit entstehende \autoref{eq:monotonie:matrix} kann dann partiell zur \autoref{eq:monotonie:derivate} abgeleitet werden.

\begin{align}
\label{eq:monotonie:matrix}
\Gamma &= \mu  \cdot (W V  D \b g)^2 = \mu \cdot \b g^T \cdot D^T V^T W^T W V D \cdot \b g\\
\label{eq:monotonie:derivate}
\frac{\partial \Gamma}{\partial \b g} &= 2 \cdot \mu \cdot \underbrace{D^T V^T W^T W V D}_{\mbox{Matrix }C}\cdot \b g
\end{align}


Der Parameter $\mu$ ist ähnlich wie $\lambda$ ein Gewichtungsfaktor für die Monotonie-Bedingung. Das Gleichungssystem aus \ref{eq:g:lgs} kann damit um den Summanden aus \autoref{eq:monotonie:derivate} ergänzt werden.

\begin{align}
\label{eq:g:monotonie}
[M + \mu C] \cdot \b g = b
\end{align}

Zu beachten ist, dass die Matrix $C$ ebenfalls pentadiagonal ist und somit auch bei diesem \gls{LGS} die besondere Eigenschaft bestehen bleibt. Deshalb kann auch hier die LU-Zerlegung einer \gls{Pentadiagonal-Matrix} (siehe \autoref{sec:maths:lu}) verwendet werden.


%------------------------------------------------------------------------------------------------------------------
\section{Erweiterung um einen Räumlicher Glattheitsterm}
\label{sec:raeumlich}
Die Erweiterung um den räumlichen Glattheitsterm (also eine Forderung an $\b F$ sich im zweidimensionalen Bild möglichst glatt zu verhalten) ist eine sinnvolle Erweiterung, um die Berechnung der $F_i$ im Bezug auf Rauschen zu verbessern. Dieses Rauschen kann z.B. bei niedrigen Belichtungszeiten und einer damit geringen Belichtungsintensität (wenig eingetroffene Photonen) entstehen. Ziel dieser Erweiterung ist es daher das lokale Umfeld um einen Bildpunkt mit in die Berechnung einzubeziehen. Dazu wird eine räumliche Glattheit gefordert, welche (analog zum Glattheitsterm von $\b g$) mittels der ersten Ableitung ausgedrückt werden kann. Da es sich bei $\b E$ um den zweidimensionalen Bildbereich handelt, müssen die Ableitungen in $x$- und $y$-Richtung betrachtet werden. Der Vektor $\b F$ ist eine eindimensionale Darstellung des zweidimensionalen Bildbereiches ($n \times m$), wobei gilt: $i = x+y*n$ ($x \in [0,n-1], \; y \in [0,m-1]$). Die Glattheitsforderung wird dabei durch die Approximation der ersten Ableitung durch eine einseitige finite Differenz realisiert, wobei die Ränder speziell behandelt werden:

\begin{align}
\label{eq:raum:glattheit}
\tilde{\Omega} =& 
    \Phi + \Theta +
    \underbrace{
        \alpha \sum_{i\in A}
            (\overbrace{
                F_i - F_{i-1}
            }^{\mbox{Abltg. nach }x}
        )^2
        +\alpha \sum_{i=n}^{N-1}(
            \overbrace{
                F_i -  F_{i-n}
            }^{\mbox{Abltg. nach }y}
        )^2
    }_{\mbox{Glattheitsterm }\Psi}\\
    \label{eq:raum:x}
    A=& \{ i \in [0,N-1]\} \setminus \{ i \cdot k | k \in \mathbb{N}_+^0 \}
\end{align}

Auch hier muss nun wieder nach $F_i$ partiell abgeleitet werden, um das Minimum der Energiefunktion (siehe \autoref{eq:raum:glattheit}) zu bestimmen, wobei die Randbedingungen zunächst vernachlässigt werden:
\begin{align}
\label{eq:raum:derivate}
\frac{\partial \Psi}{\partial F_i} =& 2\alpha[(F_i - F_{i-1}) - (F_{i+1} - F_i) + (F_i - F_{i-n})-(F_{i+n}- F_i)]\\
=&2\alpha[4 F_i-F_{i-n} - F_{i-1} - F_{i+1} - F_{i+n}]
\end{align}

Unter vernachlässigten Randbedingungen entsteht also eine Nachbarschafts-Maske die den Einfluss der umliegenden Bildpunkte angibt (siehe \autoref{fig:raum:stencil}). 

\begin{figure}
  \begin{center}
    \begin{tabular}{c|c|c}
        \cline{2-2}
        & -1 & \\
        \hline
        \multicolumn{1}{|c|}{-1}
        & 4 & \multicolumn{1}{c|}{-1}\\
        \hline
        & -1 & \\
        \cline{2-2} 
    \end{tabular}
  \end{center}
\caption{\textit{Einfluss der umliegenden Bildpunkte} --- Räumlicher Glattheitsterm als 2D Nachbarschafts-Maske.}
\label{fig:raum:stencil}
\end{figure}

Um nun das gesamte Gleichungssystem für $F_i$ aufzustellen, müssen zunächst noch die Terme $\Theta$ und $\Phi$ und ihre partiellen Ableitungen betrachtet werden:
\begin{align}
\frac{\partial \Theta}{\partial F} =& 0\\
\Phi =&\sum_{i=0}^{N-1} \sum_{j=0}^{P-1} w^2(Z_{ij})[\b g(Z_{ij}) - F_i - \ln \Delta t_j]^2\\
\frac{\partial \Phi}{\partial F_k} =& 2 \sum_{j=0}^{P-1} w^2(Z_{kj})[\b g(Z_{kj}) -F_k-\ln \Delta t_j]\\
\label{eq:raum:phi}
=& 2 \underbrace{
		\sum_{j=0}^{P-1} w^2(Z_{kj})[\b g(Z_{kj}) -\ln \Delta t_j]
	}_{
		\mbox{Vektoreintrag }b_k
	} 
	- 2 \underbrace{
		\sum_{j=0}^{P-1} w^2(Z_{kj})
	}_{
		\mbox{Matrixeintrag } H_{k,k}
	}
	F_k\\
\label{eq:raum:phi:matrix}
\partial \Phi =& 2 \b b - 2 H \cdot \b F
\end{align}


Durch Betrachtung der Randbedingungen kann nun aus den Gleichungen \ref{eq:raum:derivate} und \ref{eq:raum:phi} die Matrix $R$ für die Einbindung der räumlichen Glattheitsforderung erstellt werden. Diese ist eine $N \times N$ Matrix, die in Blöcken der Größe $n \times m$ aufgeteilt werden kann. Ein solcher Block auf der Diagonalen der Matrix  steht jeweils für eine Reihe von Bildpunkten im Bild (siehe \autoref{fig:raum:matrix}). 

Auch die Addition der Gleichungen \ref{eq:raum:derivate} und \ref{eq:raum:phi} kann wieder in Matrixschreibweise notierter werden und ergibt unter Berücksichtigung der Randbedingungen dann das nachfolgende Gleichungssystem für die Berechnung von $\b F$: 

\begin{align}
2 H \cdot \b F + 2 \alpha R\cdot \b F =& 2 \b b \\
\label{eq:raum:res}
(H+\alpha R)\cdot \b F =& \b b
\end{align}

Das Gleichungssystem aus \ref{eq:raum:res} ist symmetrisch, quadratisch und positiv semidefinit. Aufgrund dieser Eigenschaften kann beim Lösen des \gls{LGS} das schnell konvergierende SOR-Verfahren (siehe \autoref{sec:maths:sor}) verwendet werden. 

\begin{figure}
  \begin{center}
\begin{align*}
    \left(
    \begin{array}{cccc|cccc|cccc|cccc}
    2 & -1 &   &    &-1 & & & & & & & & &    \\
    -1 & 3 & -1 &    & &-1 & & & && & & &    \\
    & -1 & 3 & -1    & & & -1 & & & & & & &    \\
    & & -1 & 2      & & & & -1 & & && & & &    \\
    \hline
    -1& & & &       3& -1 & & &     -1& & & &    \\
    & -1& & &       -1&4& -1 & &     &-1& & & &    \\
    & & -1&         & & -1 & 4 & -1& &&-1& & & &    \\    
    & & &-1         & & & -1 & 3 &  &&&-1& & & &    \\
    \hline
    & & & &    -1& & & &       3& -1 & & &     -1\\
    & & & &    & -1& & &       -1&4& -1 & &     &-1\\
    & & & &    & & -1&         & & -1 & 4 & -1& &&-1\\    
    & & & &    & & &-1         & & & -1 & 3 &  &&&-1\\
    \hline
    & & & &    & & & &    -1& & & &       2& -1\\
    & & & &    & & & &    & -1& & &       -1&3& -1\\
    & & & &    & & & &    & & -1&         & & -1 & 3 & -1\\    
    & & & &    & & & &    & & &-1         & & & -1 & 2\\
    \end{array}
    \right)
\end{align*}
\end{center}
\caption{\textit{Schematischer Aufbau der Matrix $R$} --- Berechnung von $F_i$ mit räumlicher Glattheit am Beispiel eines $4 \times 4$ Bildes.}
\label{fig:raum:matrix}
\end{figure}


%------------------------------------------------------------------------------------------------------------------
\section{Erweiterung um Robustheit}
\label{sec:robustheit}

Wie im \autoref{algo:schwachstellen:robustheit} bereits beschrieben, setzt das Verfahren von Debevec und Malik nur quadratische Bestrafungsterme ein. Diese reduzieren die Auswirkungen von Gauß-Rauschen auf den Eingabebildern. Bei anderen Messungenauigkeiten (wie z.B. Rauschen) ist ein subquadratischer Bestrafungsterm aus Sicht der Robustheit des Verfahrens besser geeignet, da hier die starken Ausreißer weniger stark bestrafend wirken. Für die Erweiterung um Robustheit werden die quadratischen Bestrafungsterme an den gewünschten Stellen durch die subquadratischen ersetzt. 

Die hier verwendete differenzierbare Approximation der Betragsfunktion $\varphi(s^2)$ (siehe \autoref{eq:penalty:non-linear}) kommt in den nächsten Abschnitten häufig in ihrer ersten Ableitung vor:
\begin{align*}
\varphi'(s^2) &= \frac{1}{2\sqrt{s^2+\epsilon^2}}
\end{align*}

Nachfolgend werden nun die einzelnen Terme der Energiefunktion um den oben genannten subquadratischen Bestrafungsterm ergänzt.
% --------------------------------------------------------------------------------------------------------------
\subsection{Subquadratische Bestrafungsfunktion im Monotonie- oder Glattheits-Term von $\b g$}
An den Termen für die Glattheit von $\b g$ und die Monotonie-Forderung an $\b g$ (siehe \autoref{sec:monotonie}) ergeben die subquadratischen Bestrafungsterme keinen besonderen Sinn, da diese hier zu stückweise linearen Kurven bzw. stückweise monotonen Funktionen führen würden. Deshalb wurden diese Terme nicht erweitert.


% --------------------------------------------------------------------------------------------------------------
\subsection{Subquadratische Bestrafungsfunktion im Datenterm von $\b g$ und $\b F$}
\label{subsec:robust:e:daten}

Der Datenterm von $\b g$ berücksichtigt bisher keine Ausreißer. Sind also starke Ausreißer in den Bildern der Belichtungsserie zu finden (wie z.B. Rauschen), dann werden diese den Datenterm quadratisch beeinflussen. Besser wäre es hier große Ausreißer weniger stark zu gewichten.
Hier kommen die subquadratischen Bestrafungsfunktionen zum Einsatz, die die Energiefunktion aus \autoref{eq:energy:weights} erweitert:
\begin{align}
\label{eq:energy:robust}
\tilde{\Omega} &= 
    \underbrace{\sum_{i=0}^{N-1} \sum_{j=0}^{P-1} w^2(Z_{ij})
    \cdot \varphi([\b g(Z_{ij}) - F_i - \ln \Delta t_j]^2)}_{\mbox{Datenterm mit Robustheit }\tilde{\Phi}}
    + \underbrace{\lambda  \sum_{z=Z_{min}+1}^{Z_{max}-1} [w(Z_{ij}) \cdot \b g''(z)]^2}_{\mbox{Glattheitsterm für }g}
\end{align}

Dieses wird dann wieder partiell nach $\b g(k)$ und $F_i$ abgeleitet, um den Optimierungsansatz zu lösen:
\begin{align}
\frac{\partial \tilde{\Phi}}{\partial \b g(k)}  &= 
    2 w^2(k) \sum_{i=0}^{N-1} \sum_{j=0}^{P-1}\delta_{Z_{ij}=k} 
    \underbrace{
        \varphi'(
            [\b g(k)-F_i - \ln \Delta t_j]^2
        )
    }_{\mbox{wird festgehalten}}
    (\b g(k)-F_i - \ln \Delta t_j)
    \\
    & = \underbrace{
        2w^2(k)\sum_{i=0}^{N-1} \sum_{j=0}^{P-1}  
            \delta_{Z_{ij}=k}
            \varphi'(
                [\b g(k)-F_i - \ln \Delta t_j]^2
            )
    }_{\mbox{Matrixeintrag } \tilde{a}_k}\b g(k) \nonumber \\
    &\qquad -  
    \underbrace{
        2w^2(k)\sum_{i=0}^{N-1} \sum_{j=0}^{P-1} 
            (F_i +\ln \Delta t_j)
            \varphi'(
                [\b g(k)-F_i - \ln \Delta t_j]^2
            )
            \delta_{Z_{ij}=k}
    }_{\mbox{Vektoreintrag }\tilde{b}_k}
\end{align}

Das so entstehende Gleichungssystem ist durch die von $\b g$ und $\b F$ abhängigen Faktoren $\varphi'$ nicht mehr linear. Um das nichtlineare Gleichungssystem in eine Serie von linearen Gleichungssystemen zu übertragen, werden die vorkommenden Bestrafungsfaktoren $\varphi'([\b g(k)-F_i - \ln \Delta t_j]^2)$ festgehalten und nach jedem Schritt neu aus den alten Werten von $\b g$ und $F_i$ berechnet. 

Durch diesen Schritt kann das nichtlineare Gleichungssystem auch weiterhin mit der bereits beschriebenen LU-Zerlegung (siehe \autoref{sec:maths:lu}) gelöst werden, jedoch werden nun innere Iterationen des Verfahrens benötigt (siehe \autoref{alg:alternierend:extended}).

Die Koeffizienten $\tilde a_k$ und $\tilde b_k$ ersetzen dabei die Matrix- bzw. Vektoreinträge des Gleichungssystemes aus \autoref{eq:matrix:data}. Der Glattheitsterm $\Theta$ bleibt zusammen mit seinen partiellen Ableitungen identisch. 

Diese Erweiterung muss nun auch noch bei der Berechnung von $F_i$ berücksichtigt werden. Auch hierzu wird die Energiefunktion $\tilde{\Omega}$ (siehe \autoref{eq:energy:robust}) wieder partiell nach $F_i$ abgeleitet. Aus der \autoref{eq:fi:basic} entsteht dann bei aktiviertem subquadratischem Bestrafungsterm die neue Berechnung von $F_i$:

\begin{align}
    \label{eq:f_i:robust}
    F_i 	&= \frac{
        \sum_{j=0}^{P-1} 
            w^2(Z_{ij})
            (\b g(Z_{ij})-\ln \Delta t_j)
            \varphi'(
                [\b g(Z_{ij})-F_i - \ln \Delta t_j]^2
            )
    }
    {
        \sum_{j=0}^{P-1} 
            w^2(Z_{ij})
            \varphi'(
                [\b g(Z_{ij})-F_i - \ln \Delta t_j]^2
            )
    }
\end{align}

\begin{Algorithmus} %Die Umgebung nur benutzen, wenn man den Algorithmus ähnlich wie Graphiken von TeX platzieren lassen möchte
\caption{Erweitertes alternierendes Lösen nach $g(k)$ und $F_i$ mit Haupt- und Inneniterationen. Das nichtlineare Gleichungssystem wurde in eine Serie von linearen Gleichungssystemen aufgeteilt.}
\label{alg:alternierend:extended}
\begin{algorithmic}
\Function{SolveHDR}{$Z_{ij}$, $\ln \Delta t_j$, $N$, $P$}
	\State $g \gets initG()$
	\While{$g$ changes} 
		\Repeat
		    \State $F \gets solveF(F, g, Z_{ij}, \ln \Delta t_j, N, P)$
		\Until{$F$ has not changed significantly} 
		\Repeat
			\State $g \gets solveG(F, g, Z_{ij}, \ln \Delta t_j, N, P)$
		\Until$g$ has not changed significantly
	\EndWhile
	\State \Return [$g$, $F$]
\EndFunction
\end{algorithmic}
\end{Algorithmus}






% --------------------------------------------------------------------------------------------------------------
\subsection{Subquadratische Bestrafungsfunktion im räumlichen Glattheitsterm von $\b F$}
\label{subsec:robust:e:raum}
Die subquadratischen Bestrafungsfunktionen machen auch bei der Betrachtung des räumlichen Glattheitsterms für $\b F$ 
Sinn. Durch die weniger starke Gewichtung von starken Ausreißern -- wie sie z.B. typischer Weise an Kanten in Bildern vorkommen -- können Kanten im Bild besser erhalten werden.

Die Grundlage hierfür bildet der Glattheitsterm $\Psi$ aus der \autoref{eq:raum:glattheit}. Die darin vorkommenden quadratischen Bestrafungsterme werden nun durch die subquadratische Bestrafungsfunktion $\varphi(s^2) = \sqrt{s^2+\epsilon^2}$ ersetzt, was zum Term $\tilde{\Psi}$ führt:

\begin{align}
\label{eq:robust:raum}
\tilde{\Psi} =& 
        \alpha \sum_{i\in A}
            \varphi((F_i - F_{i-1})^2)
        +\alpha \sum_{i=n}^{N-1}\varphi([F_i - F_{i-n}]^2)
\end{align}

Hierbei wurden die Ränder des Bildes über die definierte Menge $A= \{ i \in [0,N-1]\} \setminus \{ i \cdot k | k \in \mathbb{N} \}$ behandelt.

Dies muss nun wieder nach $F_i$ partiell abgeleitet werden, wobei zunächst die Randbedingungen vernachlässigt wurden:

\begin{align}
\frac{\partial \tilde \Psi}{\partial F_i} =& 2\alpha[ \nonumber\\
    & \qquad + \varphi'((F_i - F_{i-1})^2)     \cdot (F_i - F_{i-1}) \nonumber\\
    & \qquad - \varphi'((F_{i+1} - F_{i})^2)   \cdot (F_{i+1} - F_i) \nonumber\\
    & \qquad + \varphi'((F_i - F_{i-n})^2)     \cdot (F_i - F_{i-n})\nonumber\\
    & \qquad - \varphi'((F_{i+n} - F_{i})^2)   \cdot (F_{i+n}- F_i)\nonumber\\
    ]\\
=& 2\alpha[ \nonumber\\
    & \qquad - \varphi'((F_i - F_{i-1})^2)     \cdot F_{i-1} \nonumber\\
    & \qquad - \varphi'((F_{i+1} - F_{i})^2)   \cdot F_{i+1} \nonumber\\
    & \qquad - \varphi'((F_i - F_{i-n})^2)     \cdot F_{i-n} \nonumber\\
    & \qquad - \varphi'((F_{i+n} - F_{i})^2)   \cdot F_{i+n} \nonumber\\
    & \qquad + \{\varphi'((F_i - F_{i-1})^2) + \varphi'((F_{i+1} - F_{i})^2) +\varphi'((F_i - F_{i-n})^2) + \varphi'((F_{i+n} - F_{i})^2)\} \cdot F_i \nonumber\\
    ]
\end{align}

Daraus lässt sich wieder ein Nachbarschafts-Maske erstellen, welche die Randbedingungen noch nicht berücksichtigt (siehe \autoref{fig:robust:raum:stencil}). Wenn nun die Randbedingungen berücksichtigt werden, kann die Matrix $\tilde R$  aufgestellt werden, die der vorheringen Matrix (siehe \autoref{fig:raum:matrix}) strukturell ähnelt. An den Rändern fallen entsprechend die Masken-Einträge an den Seiten weg und treten damit auch nicht im zentralen Pixel -- welches die positive Summe der Koeffizienten der Umgebungspixel enthält -- auf. Auch in dieser Erweiterung wird $\varphi'(s^2)$ vorab berechnet und dann regelmäßig aktualisiert um das nichtlineare in eine Serie von linearen Gleichungssystemen umzuwandeln.

\begin{figure}[H]
  \begin{center}
    \begin{tabular}{c|c|c}
        \cline{2-2}
        & $-\varphi'((F_i - F_{i-n})^2)$ & \\
        \hline
            \multicolumn{1}{|c|}{$-\varphi'((F_i - F_{i-1})^2)$}
            & \shortstack{$\varphi'((F_i - F_{i-1})^2) + \varphi'((F_{i+1} - F_{i})^2) $ \\
              $ +\varphi'((F_i - F_{i-n})^2) + \varphi'((F_{i+n} - F_{i})^2)$} & 
            \multicolumn{1}{c|}{$\varphi'((F_{i+1} - F_{i})^2)$}\\
        \hline
        & $-\varphi'((F_{i+n} - F_{i})^2)$ & \\
        \cline{2-2} 
    \end{tabular}
  \end{center}
\caption{\textit{Einfluss der umliegenden Bildpunkte} --- Räumlicher Glattheitsterm mit der Erweiterung durch subquadratische Bestrafungsterme.}
\label{fig:robust:raum:stencil}
\end{figure}

Das daraus entstehende Gleichungssystem in Matrix-Schreibweise ähnelt dem aus \autoref{eq:raum:res}, lediglich die Koeffizienten der Matrix $\tilde R$ unterscheiden sich vom bisherigen Ansatz:
\begin{align}
\label{eq:robust:raum:lgs}
2 H \cdot \b F + 2 \alpha \tilde R\cdot \b F =& 2 \b b \\
(H+\alpha \tilde R)\cdot \b F =& \b b
\end{align}






% --------------------------------------------------------------------------------------------------------------
\subsection{Subquadratische Bestrafungsfunktion im Daten- und Glattheitsterm von $\b E$ }
Um bei der Berechnung von $F_i$ sowohl im Datenterm, als auch im Glattheitsterm robuste Bestrafungsfunktionen zu verwenden, müssen die Ergebnisse aus \autoref{subsec:robust:e:daten} und \autoref{subsec:robust:e:raum} kombiniert werden.


\begin{align}
\tilde{\Omega} &= 
    \underbrace{\sum_{i=0}^{N-1} \sum_{j=0}^{P-1} w^2(Z_{ij})
    \cdot \varphi([\b g(Z_{ij}) - F_i - \ln \Delta t_j]^2)}_{\mbox{Datenterm mit Robustheit }\tilde{\Phi}}
    + \underbrace{\lambda  \sum_{z=Z_{min}+1}^{Z_{max}-1} [w(Z_{ij}) \cdot \b g''(z)]^2}_{\mbox{Glattheitsterm für }g} \nonumber\\
    & + \underbrace{
        \alpha \sum_{i\in A}
            \varphi((F_i - F_{i-1})^2)
        +\alpha \sum_{i=n}^{N-1}\varphi((F_i - F_{i-n})^2)
    }_{\mbox{räumlicher Glattheitsterm mit Robustheit }\Tilde \Psi}
\end{align}

Die \autoref{eq:f_i:robust} kann ebenfalls so umgeformt werden, dass ein LGS entsteht. 
\begin{align}
    & 2 \underbrace{
        \sum_{j=0}^{P-1} 
            w^2(Z_{ij})
            \varphi'(
                [\b g(Z_{ij})-F_i - \ln \Delta t_j]^2
            )
    }_{\mbox{Matrixeintrag }\tilde h_i}
    F_i = \nonumber \\
    &\qquad 2 \underbrace{
        \sum_{j=0}^{P-1} 
            w^2(Z_{ij})
            (\b g(Z_{ij})-\ln \Delta t_j)
            \varphi'(
                [\b g(Z_{ij})-F_i - \ln \Delta t_j]^2
            )
    }_{\mbox{Vektoreintrag } \tilde b_i}\\
    &
    2 \underbrace{
        \begin{pmatrix}
            \ddots & &\\
            & \tilde h_i & \\
            & & \ddots
        \end{pmatrix}
    }_{\mbox{Matrix }\tilde H}
    \cdot
    \begin{pmatrix}
        \vdots\\ F_i \\ \vdots
    \end{pmatrix}
    =
    2 \underbrace{
        \begin{pmatrix}
            \vdots\\ \tilde b_i \\ \vdots    
        \end{pmatrix}
    }_{\mbox{Vektor }\tilde{\b b}}\\
    & 2 \tilde H \cdot \b F = 2 \tilde{\b{b}}
\end{align}

Dieses Gleichungssystem wird nun mit der partiellen Ableitung von $\tilde \Psi$ kombiniert (siehe \autoref{eq:robust:raum:lgs}), was zu folgendem neuen System führt:

\begin{align}
2 \tilde H \cdot \b F + 2 \alpha \tilde R\cdot \b F =& 2 \tilde{\b b} \\
(\tilde H+\alpha \tilde R)\cdot \b F =& \tilde{\b b}
\end{align}

Durch die Matrix $\tilde R$ ist dieses Gleichungssystem jedoch erneut nichtlinear und muss wieder in eine Serie von linearen Gleichungssystemen umgeformt werden, bei denen sich nach jedem Schritt die Koeffizienten $\varphi'$ aktualisieren. Strukturell entspricht dieses Gleichungssystem dem aus \autoref{sec:raeumlich}, da die Matrix $\tilde H$ eine Diagonalmatrix mit positiven Einträgen ist. Für die Einzelschritte enstehen daher wieder positiv semidefinite und quadratische lineare Gleichungssysteme, die mit dem \gls{SOR}-Verfahren gelöst werden können.


% --------------------------------------------------------------------------------------------------------------
\section{Lösung der Gleichungssysteme}
\label{sec:solvers}
Grundsätzlich hat es der Algorithmus mit zwei verschiedenen Matrix-Strukturen zu tun. Bei der Berechnung von $\b g$ wird die strukturelle Eigenschaft der Matrix $M$ ausgenutzt um ein schnelles Lösen mittels der LU-Zerlegung zu gewährleisten.

Bei der Erweiterung des Ansatzes um einen räumlichen Glattheitsterm (siehe \autoref{sec:raeumlich}) tritt außerdem eine positive semidefinite Matrix auf, die gut durch das \gls{SOR}-Verfahren gelöst werden kann. Beide Verfahren werden hier kurz vorgestellt.



% --------------------------------------------------------------------------------------------------------------
\subsection{LU-Zerlegung einer Pentadiagonal-Matrix}
\label{sec:maths:lu}
Die Matrix $M$ aus \autoref{eq:g:lgs} ist pentadiagonal. Das bedeutet, es sind nur die zentralen fünf Diagonal-Elemente der Matrix besetzt. Hier kommt eine besonders schnelle Variante der LU-Zerlegung zum Einsatz.

Die LU-Zerlegung ist ein Verfahren, bei dem eine quadratische Matrix $A$ in die beiden Dreiecksmatritzen $L$ und $U$ zerlegt wird. Das besondere an diesem Verfahren ist, dass die nichttrivialen Elemente (Einträge ungleich null) in der Matrix $L$ (engl. lower) sich nur in der unteren linken bzw. bei der Matrix $U$ (engl. upper) nur in der oberen rechten Hälfte befinden. Die Diagonaleinträge von $L$ haben alle den Wert eins. 

In diesem speziellen Fall ist bekannt, dass die Matrix nur fünf besetzte Diagonalen hat. Diese Struktur ist sehr ähnlich zu der von tridiagonal Matrizen, für die der \texttt{Thomas-Algorithmus} \cite[S. 130f]{Westermann2008} ein gängiges direktes Lösungsverfahren ist. Basierend auf diesem Verfahren wurde eine Zerlegung für pentadiagonal Matrizen entwickelt, die zu der folgenden Struktur der Matritzen $U$ und $L$ führt:

\begin{align}
A &= L \cdot U \\
\label{eq:lu:structure}
\begin{pmatrix}
A_{ij}\\
\end{pmatrix}
&= 
\begin{pmatrix}
1 & 0 &  \\
l_1 & 1 & 0 &\\
k_2 & l_2 & 1 & 0 &\\
0 & k_3 & l_3 & 1 & 0 &\\
  &   \ddots  & \ddots & \ddots & \ddots\\
  & & 0& k_n & l_n & 1\\
\end{pmatrix}
\cdot
\begin{pmatrix}
m_0 & r_0 & p_0 & 0 &  \\
0 & m_1 & r_1 & p_1 & 0 &  \\
 & \ddots& \ddots & \ddots & \ddots & 0\\
 & & \ddots&\ddots&\ddots & p_{n-2}\\
 & & &\ddots&\ddots & r_{n-1}\\
&&  & &0& m_n 
\end{pmatrix}
\end{align}

Daraus lässt sich dann der \autoref{alg:LU} herleiten, der eine pentadiagonale Matrix $A$ und einen Vektor $\b b$ als Eingabe hat und den Vektor $\b x$ zurückgibt, sodass gilt $A \cdot \b x = \b b$. Das darin enthaltende Lösen des LGS $A\cdot \b x = \b b$ geschieht mittels der Vorwärts-Eliminierung und der Rückwärts-Substitution. 

Eine Pivotisierung der Spalten ist nicht notwendig, da die Diagonal-Einträge der Matrix bereits die betragsmäßig größten Werte einer Spalte sind. Der komplette Algorithmus ist in Pseudocode im Anhang zu finden (siehe \ref{alg:LU}).



% --------------------------------------------------------------------------------------------------------------
\subsection{SOR-Algorithmus}
\label{sec:maths:sor}

Für die Erweiterung um einen räumlichen Glattheitsterm (siehe \autoref{sec:robustheit}) muss außerdem noch ein weiterer Typ Matrix gelöst werden. Das dabei entstehende Gleichungssystem kann nicht so effizient mit der LU-Zerlegung gelöst werden, da die dabei entstehende Matrix nicht pentadiagonal und außerdem sehr groß ist ($N \times N$). 

Hierfür ist das \gls{SOR}-Verfahren besser geeignet. Bei Matrizen, die quadratisch, positiv definit, symmetrischen und dünn besetzt sind, stellt dieses Verfahren eine Verbesserung gegenüber dem Gauß-Seidel-Verfahren dar. Der reelle Parameter $\omega \in (0,2)$ sorgt dafür, dass das Verfahren schneller konvergiert. Das Gauß-Seidel- und das \gls{SOR}-Verfahren sind identisch für $\omega = 1 $.

Die Lösung für $x$ wird komponentenweise und iterativ nach folgender Vorschrift bestimmt:
\begin{align}
x_k^{m+1} = (1-\omega)x_k^m+ \frac{\omega}{a_{kk}}(b_k - \sum_{i>k} a_{ki}x_i^m - \sum_{i<k} a_{ki}x_{i}^{m+1}) ,\; k \in [1, n]
\end{align}

Die Implementierung des Verfahrens verwendet als Abbruchkriterium die Maximal-Norm $r_{max}$ des Residuum-Vektors $\b r$ mit $\b r = A \cdot \b x - \b b$. Diese wird nach jeder Iteration $m$ mit $r_{max}^m := \max_{i\in [1,n]} |r_i^m| < \delta_1$ berechnet. Falls sowohl das Residuum  als auch die Differenz der Werte zweier aufeinander folgender Iterationen kleiner als die vorgegebenen Schranken sind, so terminiert das Verfahren \cite[S. 143]{Westermann2008}. In dieser Implementierung wurde außerdem eine maximale obere Schranke für die Anzahl der Iterationen angegeben.


